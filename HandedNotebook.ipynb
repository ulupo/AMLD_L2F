{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMLD workshop by L2F – Learn to Forecast\n",
    "\n",
    "Welcome to the \"Machine Learning Competition: Tennis Analysis\" workshop at AMLD 2019, organized by [L2F – Learn to Forecast](https://www.l2f.ch/)!\n",
    "\n",
    "Starting from Jeff Sackman's crowdsourced [Match Charting Project](https://github.com/JeffSackmann/tennis_MatchChartingProject) dataset, we have put together for you a dataset containing detailed shot-by-shot descriptions of a large collection of points played between the Swiss tennis star Roger Federer and his historical rival Rafael Nadal (RN). The information recorded includes the type of shot, direction of shot, depth of returns, types of errors, and more. This is better explained below; we have also put together some preliminary data preparation to help you get started.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this workshop is for you to come up with an optimized Phederos – the god of tennis – who will be able to destroy his ancient human rival. Do you think you can beat the beast?\n",
    "\n",
    "From a more technical perspective, we ask you to provide a strategy function which, given an opponent's shot, will return what you believe to be an optimal response shot. Your answer must be in the form of a JSON dictionary as follows: each key is an opponent's shot, and the corresponding value is a list from which we will uniformly sample your response. **a dictionary of probabilities (i.e., its values must all sum to 1)**\n",
    "\n",
    "For more clarity, let us consider an example of such a strategy (the strings denote shot types which are better explained below):\n",
    "\n",
    "*strat* = {'f3': ['b2', 'b2', 'b3', 'v1'], 'f1': ['f2'], ...}.\n",
    "\n",
    "The keys in this dictionary are shots RN can produce. Suppose RN is performing a forehand on your backhand (the code for this shot is 'f3'); *strat* would reply to this shot in a *probabilistic* way as follows: \n",
    "- 'b2' with probability 1/2,\n",
    "- 'b3' with probability 1/4,\n",
    "- 'v1' with probability 1/4.\n",
    "\n",
    "On the other hand, the same strategy replies *deterministically* to 'f1' (which is a forehand on our forehand), since we say 'f2' (a forehand straight to RN) with probability 1. In this way, your strategy can incorporate simple deterministic and more complex probabilistic decision-making in an arbitrary way.\n",
    "\n",
    "## Testing environment\n",
    "\n",
    "You have to beat a stochastic model which replies to your shots based on past statistics, but never replies with shots which have historically occurred too rarely. More precisely, this simulation environment will react based on the counting statistics of outcomes to (human) Federer's shots. By 'outcome' here we mean either:\n",
    "- a simple reply shot or serve by historical RN (this is perhaps a bit confusing at first, but we consider a player's serve as a 'reply' to the opponent's 'waiting');\n",
    "- a 'termination token', e.g. '*' for a winning shot, meaning that RN could not respond to your winning shot and the point terminates, or '@' indicating that with your shot you made an unforced error and lost the point – but note that such tokens can include more detailed information than this and be more than one character long;\n",
    "- a shot by RN and a termination token, concatenated in a simple string, e.g., 'f1*' would indicate that our simulated RN replied with a winning forehand shot – ouch!\n",
    "\n",
    "The Python code for this tester can be found in the last part of this notebook.\n",
    "\n",
    "### Important remarks\n",
    "\n",
    "- The simulation environment will prompt you with shots or termination/waiting tokens from a predetermined list, which can be accessed by loading the pickle file *possible_prompts.p*. Make sure you know how to react to each of the elements in this list!\n",
    "- The pickle file *allowed_shots.p* contains a list which can be obtained from the list in *possible_prompts.p* by removing termination and waiting tokens. Replying with a string not in this list leads to losing of the point. \n",
    "- The \"past statistics\" in the stochastic model you will be fighting against come from a hold-out \"test set\" and **not** from the dataset you have access to. Make sure to build models which generalize well!\n",
    "- We will impose a time constraint on the duration of the evalutation of your policy: we expect that your policy can be evaluated on an i7 quadcore 1000000 times in less than 3 minutes.\n",
    "\n",
    "Will the true heroes of Machine Learning rise? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Jeff Sackmann's GitHub\n",
    "\n",
    "As explained above, we provide you with a pandas dataframe (*dataframe.p*), taken from Jeff Sackmann's original dataset. \n",
    "\n",
    "Each row is one point:\n",
    "- the variables 'Player1' and 'Player2' are the name of the players\n",
    "- the 'match_id' variable identifies the tournament and date\n",
    "- the varaible 'Shots' is a string containing all the shots, played alternatively from the players, during the point\n",
    "- the variable 'Shots1' are the shots played only by RF\n",
    "- the variable 'Shots0' contain the shots played only by RN\n",
    "- The 'Outcome' variable describes the outcome of the point\n",
    "- The 'Server' variable has boolean values: it is 1 in case RF is serving\n",
    "- The 'Winner' variable has boolean values: it is 1 in case RF has won the point\n",
    "\n",
    "Numbers are used to indicate direction and depth, while letters are used to specific shot types (e.g. 'f' stands for 'forehand') and error types ('n' stands for 'net'). The letter 'X' means that RN is waiting for RF to serve... don't let him wait too much! A few symbols are used for other purposes, such as types of errors (e.g. '@' means 'unforced error' and '+' indicates an approach shot).\n",
    "\n",
    "To understand the codes for each shot, we prepared an explanation file named \"Shot encodings\" with more details. You can also check [this example video](https://drive.google.com/open?id=1Q4obFagfzxkFy_mq9C5gWITQiXxBQfCf) for a visual demonstration of this way of encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical data\n",
    "\n",
    "df = pd.read_pickle('dataframe.p')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts and shots\n",
    "\n",
    "We provide here the list of possible prompts and allowed shots – historically the most common shots – that you have to use. There are many more shots in the dataframe, but we only stick to the 100 shots provided and the 40 shots provided. It means that the historical RN/tester, will only shoot with one of the 100 prompts and you can reply using only one of the 40 shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the prompts and the shots\n",
    "\n",
    "all_shots = pickle.load(open(\"allowed_shots.p\", \"rb\"))\n",
    "poss_prompts = pickle.load(open(\"possible_prompts.p\" , \"rb\"))\n",
    "\n",
    "print('Allowed shots: ', all_shots, '\\n')\n",
    "print('Possible prompts: ', poss_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing function for your model performances\n",
    "\n",
    "See the file *Aux_functions*.  The following function makes the historical RN become alive and play against you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model, shots_opo_com = aux_fn(df, poss_prompts, all_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building up the model function\n",
    "\n",
    "#################### The threshold on shots rarity ###################\n",
    "threshold = 1                                                        #\n",
    "######################################################################\n",
    "\n",
    "# Given current prompt p_t and shot s_t, return next prompt p_(t+1)\n",
    "def model(prompt, shot):\n",
    "    n_grams_ps = Model[poss_prompts.index(prompt), all_shots.index(shot)]\n",
    "    if(len(n_grams_ps) > threshold):    # exclude rare reactions\n",
    "        return np.random.choice(n_grams_ps)\n",
    "    return 'n@'   # when (p, s) never happened, return unforced error in net\n",
    "\n",
    "# Example: RN just served ('5') and we want to reply with a forehand ('f28'). This is what RN will reply (stochastic function)\n",
    "model('5', 'f28')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn to serve!\n",
    "\n",
    "You can play against the historical RN: just type in the shots and see if you can beat him! You can try first with simple shots, like 'f3' or 'b2' or even with a volley 'v1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prompt = 'X'\n",
    "while True:       ###### CAREFUL WHEN INTERRUPTING\n",
    "    shot = input()\n",
    "    next_prompt = model(current_prompt, shot)\n",
    "    print(next_prompt)\n",
    "    current_prompt = next_prompt\n",
    "    if is_win(next_prompt) == 1:\n",
    "        print('Point won!')\n",
    "        break\n",
    "    if is_win(next_prompt) == 0:\n",
    "        print('Point lost!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example and tester\n",
    "\n",
    "We provide here an example of policy and a function with which you can test your model.\n",
    "\n",
    "For testing your personal new policy, simply modify the first line of code and insert your policy dictionary. \n",
    "\n",
    "The final scoring will be done with this same function, with number_of_points_played >= 1000000 and different values of the threshold, to be sure that statistical fluctuations of the result are reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function that makes your policy (a.k.a. Phederos) play against historical RN !!\n",
    "\n",
    "############################## Modify here! ##########################\n",
    "example_policy = {'f3': ['b2', 'b2', 'b3', 'v1'], 'f1': ['f1']}\n",
    "######################################################################\n",
    "\n",
    "number_of_points_played = 150000\n",
    "\n",
    "\n",
    "serves_opponent = [shot for shot in [sh[0] for sh in shots_opo_com] if shot[0] in '456']\n",
    "points_won  = 0\n",
    "points_lost = 0\n",
    "\n",
    "\n",
    "for num in range(number_of_points_played):\n",
    "    print(num, end = '\\r')\n",
    "    # Random choice on who is serving\n",
    "    if np.random.randint(0,2) == 0 :\n",
    "        current_prompt = 'X'\n",
    "    else :\n",
    "        current_prompt = np.random.choice(serves_opponent)\n",
    "    while True:\n",
    "        shot = np.random.choice(example_policy.get(current_prompt,['5']))\n",
    "        next_prompt = model(current_prompt, shot)\n",
    "        current_prompt = next_prompt\n",
    "        if is_win(current_prompt) == 1:\n",
    "            points_won  += 1\n",
    "            break\n",
    "        if is_win(current_prompt) == 0:\n",
    "            points_lost += 1\n",
    "            break\n",
    "            \n",
    "print('How well are we performing? '     , points_won/(points_lost + points_won))\n",
    "print('Baseline historical performance: ', 1 - (df['Winner'].sum()/len(df['Winner'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn now!\n",
    "Show us that you are up for the challenge and make your Phederos destroy the historical RN! Just be careful and do not get carried away... real challenges lie ahead of you all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
